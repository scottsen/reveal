{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Notebook\n",
    "\n",
    "This notebook demonstrates common data analysis tasks:\n",
    "- Loading and exploring data\n",
    "- Data transformation\n",
    "- Visualization\n",
    "- Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load dataset from CSV file.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with loaded data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "def explore_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Print basic statistics about the dataset.\"\"\"\n",
    "    print(\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer:\n",
    "    \"\"\"Handles data transformation operations.\"\"\"\n",
    "    \n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.original = df.copy()\n",
    "    \n",
    "    def normalize_columns(self, columns: list) -> 'DataTransformer':\n",
    "        \"\"\"Normalize specified columns to 0-1 range.\"\"\"\n",
    "        for col in columns:\n",
    "            if col in self.df.columns:\n",
    "                min_val = self.df[col].min()\n",
    "                max_val = self.df[col].max()\n",
    "                self.df[col] = (self.df[col] - min_val) / (max_val - min_val)\n",
    "        return self\n",
    "    \n",
    "    def fill_missing(self, strategy: str = 'mean') -> 'DataTransformer':\n",
    "        \"\"\"Fill missing values using specified strategy.\"\"\"\n",
    "        if strategy == 'mean':\n",
    "            self.df.fillna(self.df.mean(), inplace=True)\n",
    "        elif strategy == 'median':\n",
    "            self.df.fillna(self.df.median(), inplace=True)\n",
    "        elif strategy == 'zero':\n",
    "            self.df.fillna(0, inplace=True)\n",
    "        return self\n",
    "    \n",
    "    def remove_outliers(self, column: str, threshold: float = 3.0) -> 'DataTransformer':\n",
    "        \"\"\"Remove outliers using z-score method.\"\"\"\n",
    "        z_scores = np.abs((self.df[column] - self.df[column].mean()) / self.df[column].std())\n",
    "        self.df = self.df[z_scores < threshold]\n",
    "        return self\n",
    "    \n",
    "    def get_result(self) -> pd.DataFrame:\n",
    "        \"\"\"Get transformed DataFrame.\"\"\"\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(df: pd.DataFrame, column: str, bins: int = 30) -> None:\n",
    "    \"\"\"Plot distribution of a numeric column.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df[column], bins=bins, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_matrix(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Plot correlation heatmap for numeric columns.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    correlation = df[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter(df: pd.DataFrame, x: str, y: str, hue: str = None) -> None:\n",
    "    \"\"\"Create scatter plot with optional color grouping.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if hue:\n",
    "        sns.scatterplot(data=df, x=x, y=y, hue=hue, alpha=0.6)\n",
    "    else:\n",
    "        plt.scatter(df[x], df[y], alpha=0.6)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(f'{y} vs {x}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(df: pd.DataFrame, column: str) -> dict:\n",
    "    \"\"\"Calculate comprehensive statistics for a column.\"\"\"\n",
    "    stats = {\n",
    "        'mean': df[column].mean(),\n",
    "        'median': df[column].median(),\n",
    "        'std': df[column].std(),\n",
    "        'min': df[column].min(),\n",
    "        'max': df[column].max(),\n",
    "        'q25': df[column].quantile(0.25),\n",
    "        'q75': df[column].quantile(0.75),\n",
    "        'skewness': df[column].skew(),\n",
    "        'kurtosis': df[column].kurtosis()\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def compare_groups(df: pd.DataFrame, value_col: str, group_col: str) -> pd.DataFrame:\n",
    "    \"\"\"Compare statistics across different groups.\"\"\"\n",
    "    return df.groupby(group_col)[value_col].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create sample data\n",
    "np.random.seed(42)\n",
    "sample_data = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 80, 100),\n",
    "    'income': np.random.normal(50000, 15000, 100),\n",
    "    'score': np.random.uniform(0, 100, 100),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 100)\n",
    "})\n",
    "\n",
    "# Transform data\n",
    "transformer = DataTransformer(sample_data)\n",
    "clean_data = (transformer\n",
    "              .fill_missing('mean')\n",
    "              .normalize_columns(['score'])\n",
    "              .get_result())\n",
    "\n",
    "# Calculate statistics\n",
    "stats = calculate_statistics(clean_data, 'income')\n",
    "print(\"Income Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
